\section{Kết quả của các kỹ thuật cải tiến}
\subsection{Mô hình cải tiến}
Có thể thấy được cả hai mô hình đều có thể hội tụ sao 10 epoch, nhưng mô hình cải tiến hội tụ nhanh hơn và có loss thấp hơn so với mô hình cũ. Điều này có thể thấy rõ ở hình \ref{fig:loss_model}. Mô hình cải tiến có loss thấp hơn mô hình cũ sau 10 epoch. Điều này có thể hiểu là mô hình cải tiến học nhanh hơn và hiệu quả hơn so với mô hình cũ.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Images/Improvement results/old_new_loss.png}
    \caption{Loss của cả hai mô hình }
    \label{fig:loss_model}
\end{figure}

Điều này có thể thấy rõ hơn ở confusion matrix của cả hai mô hình ở trên tập test. Mô hình cải tiến có thể dự đoán chính xác đa số các mẫu trong tập test trong khi mô hình cũ dự đoán sai một số mẫu trong tập test.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Images/Improvement results/new_confusion_matrix.png}
    \caption{Confusion matrix của mô hình mới}
    \label{fig:confusion_matrix_new}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Images/Improvement results/old_confusion_matrix.png}
    \caption{Confusion matrix của mô hình cũ}
    \label{fig:confusion_matrix_old}
\end{figure}

Không những vậy mô hình cũng có confidence trung bình cho những mẫu đoán đúng cao hơn so với mô hình cũ. Điều này có thể thấy rõ ở hình \ref{fig:confidence_model}. Mô hình cải tiến có confidence trung bình cho những mẫu đoán đúng cao hơn mô hình cũ. 

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Images/Improvement results/old_new_confidence.png}
    \caption{Confidence của cả hai mô hình}
    \label{fig:confidence_model}
\end{figure}

Kiểm nghiệm thực tế cũng cho thấy mô hình cải tiến hoạt động tốt hơn so với mô hình cũ. Mô hình cải tiến có thể dự đoán chính xác hơn 90\%  trong khi mô hình cũ chỉ có thể dự đoán chính xác khoảng 70\% và cũng như có confidence cao hơn trong các lần dự đoán.

\subsection{Làm giàu dữ liệu}
\subsubsection{Data augmentation}
Nhóm chọn 4 kỹ thuật làm giàu dữ liệu là: Jitter, Shift, Scale và Magnitude Warp.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{Images/Improvement results/data_augmentation.png}
    \caption{Data augmentation}
    \label{fig:data_augmentation}
\end{figure}

Với mỗi kỹ thuật làm giàu dữ liệu, nhóm đã ghép 2 kỹ thuật lại với nhau để tạo ra 6 cặp kỹ thuật làm giàu dữ liệu. 
Sau cùng dữ liệu có kích thước gấp 10 lần dữ liệu ban đầu.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Images/Improvement results/data_augmentation_loss.png}
    \caption{Loss của các kỹ thuật làm giàu dữ liệu}
    \label{fig:data_augmentation_loss}
\end{figure}


\section{Kết quả thực nghiệm}
\subsection{Mô hình ban đầu}

\subsubsection{Thiết lập thực nghiệm}
\begin{itemize}
    \item \textbf{Dữ liệu sử dụng:} Dữ liệu được thu thập trực tiếp từ phần cứng và được tổng hợp lại đến khi đủ 1,680 dữ liệu thì đưa vào mô hình dự đoán.
    \item \textbf{Cấu hình mô hình:}
    \begin{itemize}
        \item Mô hình LSTM với kiến trúc gồm một lớp LSTM (128 đơn vị), một lớp Dropout (tỷ lệ 50\%), và hai lớp Dense (64 đơn vị và đầu ra 5 lớp).
        \item Hàm mất mát: \texttt{categorical\_crossentropy}.
        \item Trình tối ưu: Adam.
        \item Số epoch: 300.
        \item Kích thước batch: 4,500.
    \end{itemize}
\end{itemize}

\subsubsection{Kết quả huấn luyện và kiểm tra}
\begin{itemize}
    \item \textbf{Độ chính xác trên tập huấn luyện:} Khoảng 70\%, cho thấy mô hình đã học được một phần các đặc trưng từ dữ liệu.
    \item \textbf{Độ chính xác trên tập kiểm tra:} Khoảng 70\%, phản ánh mô hình có khả năng tổng quát hóa ở mức trung bình.
\end{itemize}

\subsubsection{Kết quả dự đoán thời gian thực}
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Images/Experimental results/model.png}
    \caption{Kết quả thực nghiệm mô hình}
    \label{fig:enter-label}
\end{figure}
\begin{itemize}
    \item Khi thử nghiệm trên dữ liệu realtime từ các cảm biến, kết quả dự đoán của mô hình cho từng nhãn dao động trong khoảng từ 0.3 đến 0.6.
    \item Với ngưỡng phân loại đúng là trên 0.5, nhiều dự đoán không vượt qua ngưỡng này, dẫn đến kết quả không đáng tin cậy trong thực tế.
\end{itemize}

\subsubsection{Phân tích kết quả}
\begin{itemize}
    \item \textbf{Mô hình hoạt động tốt hơn trên dữ liệu tĩnh:}
    \begin{itemize}
        \item Độ chính xác trên tập kiểm tra cho thấy mô hình có khả năng học và phân loại ở mức cơ bản khi sử dụng dữ liệu tĩnh.
        \item Tuy nhiên, trên dữ liệu realtime, mô hình không thể duy trì hiệu suất, đặc biệt khi các tín hiệu có nhiễu hoặc thay đổi không đồng nhất.
    \end{itemize}

    \item \textbf{Khả năng phân biệt kém:}
    \begin{itemize}
        \item Kết quả dự đoán cho thấy nhiều nhãn có xác suất gần nhau, dao động quanh ngưỡng 0.5, thể hiện mô hình không tự tin trong việc phân loại.
        \item Điều này có thể do dữ liệu huấn luyện chưa đủ phong phú hoặc chưa đại diện tốt cho các trường hợp thực tế.
    \end{itemize}

    \item \textbf{Ảnh hưởng của dữ liệu nhiễu:}
    \begin{itemize}
        \item Trong môi trường thực tế, các yếu tố như nhiễu tín hiệu, dao động tay người dùng, hoặc sự không nhất quán trong cử chỉ có thể khiến dữ liệu đầu vào khác xa so với dữ liệu huấn luyện, làm giảm hiệu quả của mô hình.
    \end{itemize}
\end{itemize}

\subsection{Áp dụng cửa sổ trượt (Sliding Window)}

Kỹ thuật cửa sổ trượt (sliding window) đã được tích hợp và thử nghiệm trong hệ thống nhận diện cử chỉ thời gian thực. Đây là một phương pháp quan trọng giúp cải thiện độ chính xác dự đoán bằng cách chia nhỏ dữ liệu đầu vào thành các đoạn có độ dài cố định và xử lý tuần tự từng đoạn, tạo điều kiện cho mô hình học máy phân tích sâu hơn các chuỗi dữ liệu liên tục. Trong mục này, kết quả thực nghiệm của kỹ thuật sliding window được trình bày thông qua việc so sánh độ chính xác dự đoán và thời gian xử lý khi thay đổi kích thước cửa sổ.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Images/Experimental results/Sliding Window.png}
    \caption{Kết quả dự đoán và thời gian trung bình ứng với các giá trị sliding window}
    \label{fig:enter-label}
\end{figure}


\subsubsection{Độ chính xác dự đoán tăng theo kích thước cửa sổ}

Biểu đồ minh họa cho thấy rằng khi kích thước cửa sổ tăng dần từ 10 đến 230, độ chính xác dự đoán của hệ thống cũng tăng đáng kể. Cụ thể: 
\begin{itemize}
    \item Với kích thước cửa sổ nhỏ (10-50), giá trị độ chính xác trung bình dao động quanh mức 0.5. Kích thước nhỏ khiến hệ thống khó khai thác đầy đủ thông tin trong chuỗi dữ liệu, dẫn đến dự đoán kém ổn định.  
    \item Khi kích thước cửa sổ tăng lên (từ 100 đến 230), giá trị độ chính xác cải thiện đáng kể, đạt mức từ 0.6 đến gần 0.7. Điều này cho thấy rằng việc cung cấp nhiều dữ liệu hơn trong mỗi bước xử lý giúp mô hình nắm bắt tốt hơn các đặc điểm quan trọng trong chuỗi thời gian, qua đó tăng khả năng nhận diện chính xác.
\end{itemize}

\subsubsection{Thời gian dự đoán giảm nhẹ khi tăng kích thước cửa sổ}

Mặc dù kích thước cửa sổ tăng, thời gian xử lý mỗi lần dự đoán giảm nhẹ từ 0.12 giây xuống 0.11 giây. Điều này có thể được giải thích bởi hai yếu tố chính:
\begin{itemize}
    \item \textbf{Hiệu quả của mô hình học máy}: Mô hình được huấn luyện tối ưu với khả năng xử lý hiệu quả các chuỗi dữ liệu dài. 
    \item \textbf{Độ ổn định của bộ đệm dữ liệu}: Khi kích thước cửa sổ lớn, dữ liệu trong bộ đệm ít thay đổi thường xuyên hơn, giảm chi phí xử lý từng khung dữ liệu mới.
\end{itemize}
Mặc dù sự thay đổi về thời gian là không đáng kể, nhưng nó cho thấy rằng kỹ thuật sliding window không gây ra ảnh hưởng tiêu cực đến tốc độ xử lý thời gian thực của hệ thống.

\subsubsection{Kết luận}

Áp dụng kỹ thuật sliding window mang lại sự cải thiện đáng kể về độ chính xác dự đoán mà không ảnh hưởng tiêu cực đến tốc độ xử lý. Sự thay đổi kích thước cửa sổ giúp mô hình học máy thích nghi tốt hơn với dữ liệu đầu vào, nâng cao hiệu quả nhận diện trong các ứng dụng thời gian thực. Phương pháp này không chỉ đáp ứng được yêu cầu thực tiễn mà còn dễ dàng tinh chỉnh để phù hợp với các hệ thống khác nhau. 


\subsection{Khôi phục dữ liệu bị mất}

Trong quá trình thử nghiệm, dữ liệu thu thập từ phần cứng được gửi đến với tốc độ rất cao, khoảng 10ns/lần cho mỗi gói gồm 7 dữ liệu. Vì các lý do khách quan trong thực tế sẽ có hiện tượng mất dữ liệu trong khi truyền. Nhóm đã thực nghiệm nhiều lần và nhận thấy có hai trường hợp chính là mất ít dòng liên tục và nhiều dòng liên tục.

\subsubsection{Dữ liệu mất ít dòng (dưới 10 dòng)}

Khi dữ liệu mất ở mức độ nhỏ, chẳng hạn dưới 10 dòng (mỗi dòng chứa 7 giá trị dữ liệu), hệ thống có thể tận dụng dữ liệu gửi đến sau để bù đắp cho khoảng dữ liệu bị thiếu mà không cần áp dụng các phương pháp khôi phục dữ liệu phức tạp. Điều này mang lại hai lợi ích chính:
\begin{itemize}
    \item \textbf{Tăng tốc độ xử lý}: Tránh việc sử dụng các thuật toán phục hồi dữ liệu tốn thời gian, đặc biệt trong các ứng dụng thời gian thực.
    \item \textbf{Giữ ổn định hệ thống}: Dữ liệu được bù đắp bởi các giá trị liền kề, đảm bảo chuỗi dữ liệu tiếp tục được phân tích mà không bị gián đoạn.
\end{itemize}

Phương pháp này dựa trên giả định rằng sự mất dữ liệu trong khoảng thời gian ngắn không ảnh hưởng nghiêm trọng đến việc nhận diện cử chỉ, nhờ vào tính chất liên tục của chuỗi dữ liệu từ phần cứng.

\subsubsection{Dữ liệu mất nhiều dòng (trên 10 dòng)}

Khi hiện tượng mất dữ liệu xảy ra trên quy mô lớn hơn, các phương pháp khôi phục dữ liệu thông thường không còn đáng tin cậy. Điều này xuất phát từ việc thiếu thông tin ngữ cảnh để tái tạo chính xác chuỗi dữ liệu bị mất. Thay vào đó, một chiến lược hiệu quả hơn được đề xuất:
\begin{itemize}
    \item \textbf{Thiết lập cơ chế timeout}: Hệ thống sẽ theo dõi thời gian không nhận được dữ liệu từ phần cứng. Nếu vượt quá một khoảng thời gian định trước (timeout), hệ thống sẽ thực hiện việc khởi động lại quy trình nhận dữ liệu từ đầu.
    \item \textbf{Lợi ích của cơ chế timeout}:
    \begin{itemize}
        \item Đảm bảo rằng hệ thống không cố gắng xử lý các chuỗi dữ liệu không đầy đủ, tránh ảnh hưởng đến độ chính xác của mô hình.
        \item Đơn giản hóa quy trình xử lý, giảm thiểu chi phí tính toán so với các phương pháp phục hồi dữ liệu phức tạp.
    \end{itemize}
\end{itemize}

\subsubsection{Kết luận}

Với tốc độ gửi dữ liệu cao từ phần cứng, hệ thống có thể tự điều chỉnh để đối phó với hiện tượng mất dữ liệu mà không cần áp dụng các kỹ thuật khôi phục phức tạp. Đối với dữ liệu bị mất ít dòng, dữ liệu gửi đến sau có thể bù lại được, đảm bảo tính liên tục. Ngược lại, khi mất quá nhiều dữ liệu, cơ chế timeout sẽ đảm bảo rằng hệ thống nhận dữ liệu lại từ đầu, giữ vững tính ổn định và chính xác trong các ứng dụng thời gian thực.

Chiến lược này tối ưu hóa hiệu suất của hệ thống, giảm thiểu chi phí xử lý và phù hợp với yêu cầu của các ứng dụng nhận diện cử chỉ trong thực tế.




\subsection{1}
Data được thu thập sau đó được phân bổ với tỉ lệ 80-20, 80\% lượng data được sử dụng để train mô hình, 20\% được sử dụng để kiểm tra kết quả sau khi huấn luyện

Nhìn chung kết quả của các kỹ thuật đều giúp mô hình hội tụ nhanh hơn khi sử dụng tập dữ liệu ban đầu. Bởi vì mô hình mới với dữ liệu ban đầu đã làm rất tốt nên việc làm giàu dữ liệu không thể hiện rõ ở mặt độ chính xác của mô hình. Tuy nhiên, có một số kỹ thuật làm giàu dữ liệu giúp mô hình hội tụ nhanh hơn so với dữ liệu ban đầu và có loss thấp hơn ví dụ như jitter.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Images/Improvement results/old_data_augmentation_loss.png}
    \caption{Loss của mô hình cũ với dữ liệu đã làm giàu}
    \label{fig:old_data_augmentation_loss}
\end{figure}

Điều này được thể hiện rõ hơn khi nhóm áp dụng tập dữ liệu đã làm giàu vào mô hình cũ. Mô hình cũ với dữ liệu đã làm giàu có thể hội tụ nhanh và có loss thấp hơn so với mô hình cũ với dữ liệu ban đầu với jitter là mô hình có loss thấp nhất - điều tương tự đã quan sát được ở mô hình mới.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Images/Improvement results/old_data_augmentation_accuracy.png}
    \caption{Accuracy của mô hình cũ với dữ liệu đã làm giàu}
    \label{fig:old_data_augmentation_accuracy}
\end{figure}

Với mô hình cũ, dữ liệu đã làm giàu giúp mô hình có độ chính xác cao hơn so với dữ liệu ban đầu với độ cải thiện từ 80\% lên 100\% đối với tập test. Nhìn chung các mô hình với dữ liệu đã làm giàu đều có độ chính xác cải thiện rõ rệt so với dữ liệu ban đầu. Kiểm nghiệm thực tế cũng cho thấy cải thiện từ 5\% đến 10\% so với dữ liệu ban đầu.

\subsection{Transfer learning}
Bước đầu thực hiện huấn luyện mô hình với tập dữ liệu ASL Data Glove giữ nguyên 11 đặc trưng cho kết quả dự đoán của mô hình trên tập validation là gần mức 0.8. 

\begin{figure}[H]
    \centering
    \includegraphics[width=1.1\textwidth]{Images/Improvement results/transfer_learning_training_result_full_class.png}
    \caption{Transfer learning với 11 đặc trưng}
    \label{fig:transfer_learning_training_result_full_class}
\end{figure}


Sau đó, nhóm thực hiện biến đổi dữ liệu để phù hợp với tính chất dữ liệu của nhóm và cắt giảm từ 11 xuống còn 7 đặc trưng. Kết quả huấn luyện của mô hình giảm rõ rệt so với mô hình với 11 đặc trưng. Điều này có thể dự đoán được vì với 40 nhãn của tập dữ liệu ASL Data Glove, mô hình cần nhiều đặc trưng hơn để có thể dự đoán chính xác hơn.

\begin{figure}[H]
    \centering
    \includegraphics[width=1.1\textwidth]{Images/Improvement results/transfer_learning_training_result.png}
    \caption{Transfer learning với 7 đặc trưng}
    \label{fig:transfer_learning_training_result_7_class}
\end{figure}

Sau khi chuyển weight của mô hình đã được huấn luyện với tập dữ liệu ASL Data Glove sang mô hình mới, quá trình huấn luyện mô hình transfer learning có thấy mô hình transfer learning hội tụ nhanh hơn so với mô hình mới, loss cũng thấp hơn so với mô hình ban đầu. 

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Images/Improvement results/transfer_learning_confusion_matrix.png}
    \caption{So sánh transfer learning và mô hình mới}
    \label{fig:transfer_learning_training_result_compare}
\end{figure}

Kết quả của mô hình transfer learning ở tập test cũng cho thấy mô hình có thể dự đoán đúng nhiều hơn so với mô hình mới ban đầu. Tuy nhiên sự khác biệt là không lớn (<10 mẫu) và kiểm nghiệm thực tế cũng cho thấy sai khác <5\% giữa mô hình mới và mô hình transfer learning.


\subsection{TimeGAN}

Khác với Data augmentation, dữ liệu do TimeGAN tạo ra có chất lượng không tốt. Trực quan hóa dữ liệu đã được TimeGAN tạo ra cho thấy dữ liệu đã được TimeGAN tạo ra không giống với dữ liệu ban đầu. Với cả 7 đặc trưng dữ liệu tạo ra có nét tương đồng với dữ liệu gốc nhưng những mẫu tạo ra không giống với dữ liệu gốc. Từ hình ảnh có thể thấy rõ rằng dữ liệu tạo ra bởi TimeGAN không có tính biến thiên như dữ liệu gốc.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{Images/Improvement results/TimeGAN_f1.png}
    \caption{Trực quan hóa dữ liệu của đặc trưng 'f1'}
    \label{fig:timegan_data_f1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{Images/Improvement results/TimeGAN_f2.png}
    \caption{Trực quan hóa dữ liệu của đặc trưng 'f2'}
    \label{fig:timegan_data_f2}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{Images/Improvement results/TimeGAN_f3.png}
    \caption{Trực quan hóa dữ liệu của đặc trưng 'f3'}
    \label{fig:timegan_data_f3}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{Images/Improvement results/TimeGAN_f4.png}
    \caption{Trực quan hóa dữ liệu của đặc trưng 'f4'}
    \label{fig:timegan_data_f4}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{Images/Improvement results/TimeGAN_gx.png}
    \caption{Trực quan hóa dữ liệu của đặc trưng 'gx'}
    \label{fig:timegan_data_gx}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{Images/Improvement results/TimeGAN_gy.png}
    \caption{Trực quan hóa dữ liệu của đặc trưng 'gy'}
    \label{fig:timegan_data_gy}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{Images/Improvement results/TimeGAN_gz.png}
    \caption{Trực quan hóa dữ liệu của đặc trưng 'gz'}
    \label{fig:timegan_data_gz}
\end{figure}

Khi xét đến MSE, độ ổn định của các đặc trưng qua các mẫu là không đều nhau, một số đặc trưng sẽ có sai số toàn phương trung bình cao hơn so với các đặc trưng khác.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{Images/Improvement results/MSE_xinchao.png}
    \caption{MSE của nhãn Xin Chào}
    \label{fig:timegan_mse}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{Images/Improvement results/MSE_toi.png}
    \caption{MSE của nhãn Tôi}
    \label{fig:timegan_mse}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{Images/Improvement results/MSE_ten.png}
    \caption{MSE của nhãn Tên}
    \label{fig:timegan_mse}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{Images/Improvement results/MSE_tien.png}
    \caption{MSE của nhãn Tiến}
    \label{fig:timegan_mse}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{Images/Improvement results/MSE_tambiet.png}
    \caption{MSE của nhãn Tạm Biệt}
    \label{fig:timegan_mse}
\end{figure}

Kết quả huấn luyện cho thấy mô hình TimeGAN không ổn định cũng như là có loss cao hơn so với mô hình với dữ liệu ban đầu. Kết quả của mô hình TimeGAN trên tập test không cho thấy khác biệt nhiều so với mô hình với dữ liệu ban đầu.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Images/Improvement results/TimeGAN_loss.png}
    \caption{Loss của mô hình TimeGAN}
    \label{fig:timegan_loss}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{Images/Improvement results/TimeGAN_confusionmatrix.png}
    \caption{Confusion matrix của mô hình TimeGAN}
    \label{fig:timegan_confusion_matrix}
\end{figure}

Kiểm nghiệm thực tế cũng cho thấy mô hình TimeGAN không cải thiện được độ chính xác của mô hình so với dữ liệu ban đầu, nếu có khác biệt thì cũng không lớn.


% Data được thu thập sau đó được phân bổ với tỉ lệ 80-20, 80\% lượng data được sử dụng để train mô hình, 20\% được sử dụng để kiểm tra kết quả sau khi huấn luyện

% Chúng ta không thể đánh giá kỹ năng của mô hình chỉ từ một lần đánh giá.
% Nguyên nhân là mạng nơ-ron là ngẫu nhiên, có nghĩa là một cấu hình mô hình cụ thể khác nhau sẽ xuất hiện khi đào tạo cùng một cấu hình mô hình trên cùng một dữ liệu. Điều này là một đặc trưng của mạng, vì nó mang lại khả năng thích ứng cho mô hình, nhưng yêu cầu một quá trình đánh giá mô hình phức tạp hơn.

% Chúng ta sẽ lặp lại việc đánh giá mô hình nhiều lần, sau đó tóm tắt hiệu suất của mô hình qua từng lần chạy đó. chúng ta có thể gọi hàm evaluate\_model() tổng cộng 5 lần.Điều này sẽ dẫn đến một tập hợp các điểm đánh giá mô hình cần được tóm tắt.'\\

% \begin{lstlisting}
% >#1: 90.058
% >#2: 85.918
% >#3: 90.974
% >#4: 89.515
% >#5: 90.159
% >#6: 91.110
% >#7: 89.718
% >#8: 90.295
% >#9: 89.447
% >#10: 90.024

% [90.05768578215134, 85.91788259246692, 90.97387173396675, 89.51476077366813, 90.15948422124194, 91.10960298608755, 89.71835765184933, 90.29521547336275, 89.44689514760775, 90.02375296912113]

% Accuracy: 89.722% (+/-1.371)

% \end{lstlisting}
% Cuối cùng, mẫu các điểm đánh giá được in ra, tiếp theo là giá trị trung bình và độ lệch chuẩn. Chúng ta có thể thấy rằng mô hình đã hoạt động tốt, đạt được độ chính xác phân loại khoảng 89,7\% khi được huấn luyện trên dữ liệu thô, với độ lệch chuẩn là khoảng 1,3. Đây là một kết quả tốt ! 
% \subsection{}

% Dựa vào số động tác thực hiện và số lần mô hình xác định chính xác, cho thấy mô hình chỉ đạt kết quả khoảng 70\%: \\

% Kết quả này được thực hiện như sau:\\
% \begin{itemize}
%     \item Một động tác được duy trì trong 2.4s bằng với số frame dữ liệu được gửi đến mô hình để dự đoán
%     \item Thực hiện động tác với label 7 và 9 vì hai động tác này có data frame khá tương đồng nhau,  trong 1 phút bằng với 25 lần mô hình gửi đến model kết quả cho thấy chỉ dự đoán được 18 lần với label 7 và 17 lần với label 9
% \end{itemize}
% Những động tác có data frame khác biệt nhau ví dự như label 5 và label 0 cho ra kết quả khá chính xác, lên đến hơn 90\% dựa vào cách tính trên


