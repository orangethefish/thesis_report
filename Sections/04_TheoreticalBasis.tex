\section{Cơ sở lý thuyết}
\subsection{Giới thiệu về học máy(Machine learning)}
\indent Học máy (Machine Learning) là một nhánh quan trọng của trí tuệ nhân tạo (AI), tập trung vào việc nghiên cứu và phát triển các kỹ thuật cho phép hệ thống tự động học hỏi từ dữ liệu để giải quyết các vấn đề cụ thể mà không cần lập trình rõ ràng từng bước. Khái niệm học máy đã xuất hiện từ những năm 1950, khi các nhà khoa học lần đầu tiên thử nghiệm mô phỏng khả năng học tập của con người bằng máy tính. Tuy nhiên, phải đến đầu thế kỷ 21, học máy mới thực sự bùng nổ nhờ sự tiến bộ vượt bậc trong công nghệ phần cứng và khả năng tính toán.
\indent Trong những năm gần đây, học máy đã được thúc đẩy mạnh mẽ bởi sự phát triển của các thuật toán tiên tiến, sự gia tăng của dữ liệu lớn (Big Data) và sức mạnh xử lý của các hệ thống tính toán hiện đại. Những yếu tố này đã làm cho học máy trở thành công cụ không thể thiếu trong nhiều lĩnh vực như nhận dạng hình ảnh, xử lý ngôn ngữ tự nhiên, y tế, tài chính, và đặc biệt là IoT (Internet of Things). Với khả năng thích ứng linh hoạt và hiệu quả, học máy không chỉ mang lại giá trị thực tiễn to lớn mà còn mở ra những cơ hội mới trong nghiên cứu và ứng dụng công nghệ.

\subsection{Giới thiệu về Mạng nơ-ron hồi quy(RNN)}
\subsubsection{Tổng quan}
\indent Mạng nơ-ron hồi quy (Recurrent Neural Networks - RNN) là một loại mạng nơ-ron chuyên biệt trong học sâu, được thiết kế để xử lý dữ liệu tuần tự. Các chuỗi dữ liệu này thường mang tính liên kết, như các câu văn, chuỗi thời gian hay tín hiệu âm thanh. Đặc trưng của RNN là khả năng duy trì thông tin từ các bước trước đó trong chuỗi, nhờ vào các vòng hồi tiếp trong cấu trúc mạng. Điều này cho phép RNN mô hình hóa các mối quan hệ phức tạp và phụ thuộc giữa các thành phần trong dữ liệu.

\indent RNN hoạt động bằng cách sử dụng cùng một tập tham số trên mọi bước thời gian, tái sử dụng chúng để giảm thiểu số lượng tham số cần học. Tuy nhiên, khả năng này cũng đi kèm với thách thức, khi mạng phải đối mặt với các vấn đề như khó khăn trong việc lưu trữ thông tin xa hoặc triệt tiêu/đột biến gradient trong quá trình học.

\indent Hiện nay, mặc dù RNN vẫn được sử dụng cho nhiều bài toán liên quan đến chuỗi dữ liệu, nhưng nó đang dần được thay thế bởi các mô hình hiệu quả hơn như các mô hình dựa trên cơ chế Attention hoặc các mạng Transformer.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Images/Theoretical basis/RNN-unrolled.png}
    \caption{Minh họa một mạng nơ-ron hồi quy}
    \label{fig:enter-label}
\end{figure}

\subsubsection{Một số loại mạng nơ-ron hồi quy}
\indent Mạng nơ-ron hồi quy (RNN) có thể được cấu hình theo nhiều cách khác nhau tùy thuộc vào loại bài toán cần giải quyết. Dưới đây là các dạng cấu trúc RNN phổ biến:
\begin{itemize}
    \item \textbf{Một-nhiều (One-to-Many):} Trong cấu hình này, từ một đầu vào duy nhất, mạng tạo ra một chuỗi các đầu ra. Loại này thường được ứng dụng trong các bài toán như tạo chú thích hình ảnh, nơi mạng nơ-ron tạo ra một câu hoàn chỉnh dựa trên một hình ảnh đầu vào duy nhất.
    \item \textbf{Nhiều-một (Many-to-One):} Đây là cấu trúc mà mạng nhận một chuỗi dữ liệu đầu vào và đưa ra một đầu ra duy nhất. Một ví dụ điển hình là phân tích cảm xúc, nơi RNN nhận một đoạn văn bản và dự đoán cảm xúc tổng quát (như tích cực, tiêu cực hoặc trung tính).
    \item \textbf{Nhiều-một (Many-to-Many):} Mạng này xử lý nhiều đầu vào và tạo ra nhiều đầu ra tương ứng. Đây là cấu trúc phổ biến trong các ứng dụng dịch máy, nơi mạng nhận một câu ở ngôn ngữ nguồn và chuyển đổi nó thành một câu tương ứng ở ngôn ngữ đích.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Images/Theoretical basis/RNN_Type.jpeg}
    \caption{Một số kiểu nơ-ron hồi quy phổ biến}
    \label{fig:enter-label}
\end{figure}
\subsubsection{Vấn đề phụ thuộc xa của RNN}

\indent Một trong những đặc điểm nổi bật của mạng nơ-ron hồi quy (RNN) là khả năng tận dụng thông tin từ các bước trước trong chuỗi dữ liệu để dự đoán các bước tiếp theo. Điều này tương tự như cách con người sử dụng bối cảnh từ các đoạn văn trước để hiểu một đoạn văn hiện tại. Tuy nhiên, khả năng này của RNN không phải lúc nào cũng hiệu quả và còn phụ thuộc vào khoảng cách giữa thông tin cần thiết và thông tin hiện tại.

\indent Trong các trường hợp đơn giản, khi khoảng cách giữa dữ liệu cần ghi nhớ và thông tin hiện tại là ngắn, RNN có thể hoạt động tốt. Ví dụ, khi đọc câu "Các đám mây trên bầu trời...", thông tin về cụm từ "bầu" ngay lập tức gợi ý từ "trời". Đây là một dạng phụ thuộc ngắn hạn mà RNN có thể xử lý dễ dàng.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Images/Theoretical basis/RNN-shorttermdepdencies.png}
    \caption{Phụ thuộc ngắn hạn trên RNN}
    \label{fig:enter-label}
\end{figure}
\indent Tuy nhiên, khi cần đến các mối quan hệ phức tạp hơn với khoảng cách xa, RNN bắt đầu gặp khó khăn. Chẳng hạn, trong câu "Tôi lớn lên ở Pháp... Tôi nói tiếng Pháp rất lưu loát", thông tin gần như "Tôi nói tiếng..." không đủ để xác định đó là ngôn ngữ nào. Việc suy luận đúng cần dựa vào thông tin ở câu trước đó, "Tôi lớn lên ở Pháp". Khi khoảng cách giữa dữ liệu cần nhớ và thông tin hiện tại tăng lên, RNN thường mất khả năng ghi nhớ và học hiệu quả.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Images/Theoretical basis/RNN-longtermdependencies.png}
    \caption{Phụ thuộc dài hạn trên RNN}
    \label{fig:enter-label}
\end{figure}
\indent Nguyên nhân chính là do hiện tượng triệt tiêu gradient (vanishing gradient), khiến cho các tín hiệu từ các bước trước đó bị yếu dần trong quá trình lan truyền ngược. Điều này khiến RNN không thể lưu giữ được thông tin dài hạn, gây ảnh hưởng nghiêm trọng đến hiệu quả xử lý của mạng.


\subsection{Giói thiệu mô hình Long-short term memmory(LTSM)}
\subsubsection{Giới thiệu tổng quan}

\indent Long Short-Term Memory (LSTM) là một loại mạng nơ-ron hồi quy (RNN) đặc biệt được thiết kế để giải quyết vấn đề phụ thuộc xa trong dữ liệu tuần tự. LSTM lần đầu tiên được giới thiệu bởi Hochreiter và Schmidhuber vào năm 1997 và sau đó đã được cải tiến bởi nhiều nhà nghiên cứu khác, giúp nó trở thành một công cụ quan trọng trong lĩnh vực học sâu.

\indent Khác với RNN truyền thống, LSTM có khả năng lưu trữ thông tin trong một khoảng thời gian dài hơn nhờ vào cấu trúc độc đáo với các cổng điều khiển thông minh. Những cổng này bao gồm cổng quên, cổng đầu vào và cổng đầu ra, cho phép mô hình lựa chọn giữ lại hay loại bỏ thông tin một cách có chọn lọc. Điều này giúp LSTM khắc phục được các hạn chế như triệt tiêu hoặc bùng nổ gradient, vốn là vấn đề phổ biến trong RNN tiêu chuẩn.

\indent LSTM hoạt động hiệu quả trên nhiều bài toán khác nhau, từ xử lý ngôn ngữ tự nhiên, dự đoán chuỗi thời gian đến nhận dạng giọng nói và video. Chính sự linh hoạt và khả năng xử lý dữ liệu tuần tự dài hạn này đã khiến LSTM trở thành một lựa chọn phổ biến trong các ứng dụng học sâu.

\begin{figure}[H]
    \centering
    \includegraphics[width=14cm]{Images/Theoretical basis/LSTM.png}
\caption{Mô hình LSTM với 4 lớp tương tác}
\end{figure}
\subsubsection{Ý tưởng đằng sau LSTM}

\begin{figure}[H]
    \centering
    \includegraphics[width=14cm]{Images/Architecture/lstm1.png}
\caption{Diễn giải các kí hiệu trong đồ thị}
\end{figure}

\indent Mạng LSTM được thiết kế với mục đích giải quyết vấn đề phụ thuộc xa trong RNN bằng cách sử dụng một thành phần đặc biệt gọi là ô trạng thái (cell state). Ô trạng thái này hoạt động như một đường dẫn thẳng xuyên suốt chuỗi dữ liệu, giúp truyền tải thông tin mà không bị mất mát quá nhiều qua thời gian. Điều này giúp LSTM có thể nhớ được thông tin trong khoảng thời gian dài mà không gặp phải vấn đề triệt tiêu gradient.

\begin{itemize}
    \item Ô trạng thái (cell state) được thể hiện qua đường chạy ngang qua đỉnh đồ thị như hình vẽ bên dưới:
    \begin{figure}[H]
        \centering
        \includegraphics[width=14cm]{Images/Architecture/LSTM3-C-line.png}
    \caption{Đường đi của ô trạng thái (cell state) trong mạng LSTM}
    \end{figure}
    \item Ô trạng thái là một dạng băng chuyền chạy thẳng xuyên suốt toàn bộ chuỗi với chỉ một vài tương tác tuyến tính nhỏ giúp cho thông tin có thể truyền dọc theo đồ thị mạng nơ-ron ổn định.
    \item LSTM có khả năng xóa và thêm thông tin vào ô trạng thái và điều chỉnh các luồng thông tin này thông qua các cấu trúc gọi là cổng.
    \item Cổng là cơ chế đặc biệt để điều chỉnh luồng thông tin đi qua. Chúng được tổng hợp bởi một tầng ẩn của hàm activation sigmoid và với một toán tử nhân như đồ thị.
    \begin{figure}[H]
        \centering
        \includegraphics[width=3cm]{Images/Architecture/LSTM3-gate.png}
    \caption{Một cổng của hàm sigmoid trong LSTM}
    \end{figure}
    \item Hàm sigmoid sẽ cho đầu ra là một giá trị xác xuất nằm trong khoảng từ 0 đến 1, thể hiện rằng có bao nhiêu phần thông tin sẽ đi qua cổng. Giá trị bằng 0 ngụ ý rằng không cho phép thông tin nào đi qua, giá trị bằng 1 sẽ cho toàn bộ thông tin đi qua.
    \item Một mạng LSTM sẽ có 3 cổng có kiến trúc dạng này để bảo vệ và kiểm soát các ô trạng thái.
\end{itemize}

\subsubsection{Thứ tự các bước của LSTM}

\indent Bước đầu tiên trong LSTM sẽ quyết định xem thông tin nào chúng ta sẽ cho phép đi qua ô trạng thái (cell state). Nó được kiểm soát bởi hàm sigmoid trong một tầng gọi là tầng quên (forget gate layer). Đầu tiên nó nhận đầu vào là 2 giá trị \( h_{t-1} \)
 và \( x_{t} \)
 và trả về một giá trị nằm trong khoảng 0 và 1 cho mỗi giá trị của ô trạng thái \( \text{C}_{t-1} \)
. Nếu giá trị bằng 1 thể hiện ‘giữ toàn bộ thông tin’ và bằng 0 thể hiện ‘bỏ qua toàn bộ chúng’.

\indent Trở lại ví dụ về ngôn ngữ, chúng ta đang cố gắng dự báo từ tiếp theo dựa trên toàn bộ những từ trước đó. Trong những bài toán như vậy, ô trạng thái có thể bao gồm loại của chủ ngữ hiện tại, để cho đại từ ở câu tiếp theo được sử dụng chính xác. Chẳng hạn như chúng ta đang mô tả về một người bạn là con trai thì các đại từ nhân xưng ở tiếp theo phải là anh, thằng, hắn thay vì cô, con ấy. Tuy nhiên chủ ngữ không phải khi nào cũng cố định. Khi chúng ta nhìn thấy một chủ ngữ mới, chúng ta muốn quên đi loại của một chủ ngữ cũ. Do đó tầng quên cho phép cập nhật thông tin mới và lưu giữ giá trị của nó khi có thay đổi theo thời gian.

\begin{figure}[H]
    \centering
    \includegraphics[width=14cm]{Images/Architecture/LSTM3-focus-f.png}
\caption{Tầng cổng quên (forget gate layer)}
\end{figure}

\indent Bước tiếp theo chúng ta sẽ quyết định loại thông tin nào sẽ được lưu trữ trong ô trạng thái. Bước này bao gồm 2 phần. Phần đầu tiên là một tầng ẩn của hàm sigmoid được gọi là tầng cổng vào (input gate layer) quyết định giá trị bao nhiêu sẽ được cập nhật. Tiếp theo, tầng ẩn hàm tanh sẽ tạo ra một véc tơ của một giá trị trạng thái mới 
 mà có thể được thêm vào trạng thái. Tiếp theo kết hợp kết quả của 2 tầng này để tạo thành một cập nhật cho trạng thái.

\indent Trong ví dụ của mô hình ngôn ngữ, chúng ta muốn thêm loại của một chủ ngữ mới vào ô trạng thái để thay thế phần trạng thái cũ muốn quên đi.

\begin{figure}[H]
    \centering
    \includegraphics[width=14cm]{Images/Architecture/LSTM3-focus-i.png}
\caption{ Cập nhật giá trị cho ô trạng thái bằng cách kết hợp 2 kết quả từ tầng cổng vào và tẩng ẩn hàm tanh}
\end{figure}

\indent Đây là thời điểm để cập nhật một ô trạng thái cũ \( \text{C}_{t-1} \)
 sang một trạng thái mới \( \text{C}_{t} \)
. Những bước trước đó đã quyết định làm cái gì, và tại bước này chỉ cần thực hiện nó.

\indent Chúng ta nhân trạng thái cũ với \( f_{t} \)
 tương ứng với việc quên những thứ quyết định được phép quên sớm. Phần tử đề cử \( \tilde{\text{C}}_{t-1} \)
 là một giá trị mới được tính toán tương ứng với bao nhiêu được cập nhật vào mỗi giá trị trạng thái.

 \begin{figure}[H]
    \centering
    \includegraphics[width=14cm]{Images/Architecture/LSTM3-focus-C.png}
\caption{Ô trạng thái mới}
\end{figure}

\indent Cuối cùng cần quyết định xem đầu ra sẽ trả về bao nhiêu. Kết quả ở đầu ra sẽ dựa trên ô trạng thái, nhưng sẽ là một phiên bản được lọc. Đầu tiên, chúng ta chạy qua một tầng sigmoid nơi quyết định phần nào của ô trạng thái sẽ ở đầu ra. Sau đó, ô trạng thái được đưa qua hàm tanh (để chuyển giá trị về khoảng -1 và 1) và nhân nó với đầu ra của một cổng sigmoid, do đó chỉ trả ra phần mà chúng ta quyết định.

 \begin{figure}[H]
    \centering
    \includegraphics[width=14cm]{Images/Architecture/LSTM3-focus-o.png}
\caption{Điều chỉnh thông tin ở đầu ra thông qua hàm tanh}
\end{figure}
\subsubsection{Ưu và nhược điểm của mô hình LSTM}

\textbf{Ưu điểm}
\begin{itemize}
    \item LSTM được thiết kế đặc biệt để giải quyết vấn đề phụ thuộc dài hạn trong dữ liệu tuần tự. Nhờ vào ô trạng thái và cơ chế các cổng, LSTM có khả năng lưu trữ thông tin trong thời gian dài mà không bị mất mát như các mạng RNN truyền thống.
    \item LSTM có thể học và theo dõi các mối quan hệ phức tạp giữa các phần tử trong chuỗi dữ liệu dài, giúp giải quyết các bài toán như dịch ngôn ngữ, nhận diện giọng nói và phân tích chuỗi thời gian.
    \item Các cổng trong LSTM giúp giảm thiểu vấn đề triệt tiêu gradient, mà thường gặp phải trong các mạng RNN thông thường. Điều này cho phép mạng có thể học được thông tin từ các bước thời gian xa mà không gặp phải sự giảm sút mạnh mẽ của gradient.
    \item LSTM có thể được sử dụng trong nhiều bài toán khác nhau và có thể kết hợp với các mô hình học sâu phức tạp để tạo thành các mạng học sâu đa lớp, linh hoạt và hiệu quả trong việc xử lý các loại dữ liệu khác nhau.
\end{itemize}
\textbf{Nhược điểm}
\begin{itemize}
    \item LSTM có cấu trúc phức tạp hơn so với các mạng nơ-ron hồi quy thông thường. Việc tính toán và tối ưu các tham số trong LSTM yêu cầu tài nguyên tính toán lớn và thời gian huấn luyện dài, đặc biệt là với các mô hình có số lớp lớn và dữ liệu phức tạp.
    \item Do tính toán phức tạp và yêu cầu số lượng tham số lớn, quá trình huấn luyện mô hình LSTM có thể mất nhiều thời gian, đặc biệt là khi làm việc với bộ dữ liệu lớn.
    \item LSTM dễ gặp phải vấn đề overfitting, đặc biệt là khi sử dụng với bộ dữ liệu huấn luyện nhỏ hoặc khi mạng quá phức tạp. Điều này có thể dẫn đến việc mô hình học quá chi tiết từ dữ liệu huấn luyện mà không có khả năng tổng quát tốt trên dữ liệu mới.
    \item Mặc dù LSTM giải quyết được vấn đề triệt tiêu gradient, nhưng vấn đề gradient exploding (gradient phát triển quá mức) vẫn có thể xảy ra. Điều này có thể làm mô hình trở nên không ổn định, đặc biệt trong quá trình huấn luyện với các chuỗi dữ liệu rất dài.
\end{itemize}

\subsection{Giới thiệu về Transfer Learning}

Transfer learning (học chuyển giao) là một kỹ thuật học máy trong đó một mô hình được phát triển cho một nhiệm vụ được sử dụng lại như là điểm khởi đầu cho một mô hình trên một nhiệm vụ thứ hai. Nói cách khác, kiến thức thu được trong khi giải quyết một vấn đề được áp dụng cho một vấn đề khác, nhưng có liên quan. 

\subsubsection{Định nghĩa Transfer Learning}

Transfer learning là việc sử dụng kiến thức đã học từ một miền nguồn (source domain) để cải thiện việc học trong một miền đích (target domain) khác. Miền nguồn thường có lượng dữ liệu lớn hơn và/hoặc dễ học hơn miền đích. 

 \begin{figure}[H]
    \centering
    \includegraphics[width=14cm]{Images/Theoretical basis/Transfer_Learning.png}
\caption{Transfer learning}
\end{figure}


\subsubsection{Ứng dụng của Transfer Learning}

Transfer learning đã được ứng dụng thành công trong nhiều lĩnh vực, bao gồm:

\begin{itemize}
    \item \textbf{Thị giác máy tính:} 
        \begin{itemize}
            \item Phân loại ảnh: Xác định các đối tượng trong ảnh (chó, mèo, xe hơi,...)
            \item Nhận dạng đối tượng: Xác định vị trí của các đối tượng trong ảnh.
            \item Phân đoạn ảnh: Phân chia ảnh thành các vùng có ý nghĩa.
        \end{itemize}
    \item \textbf{Xử lý ngôn ngữ tự nhiên:}
        \begin{itemize}
            \item Phân loại văn bản: Phân loại các tài liệu văn bản (tin tức, đánh giá,...)
            \item Phân tích cảm xúc: Xác định cảm xúc được thể hiện trong văn bản.
            \item Dịch máy: Dịch văn bản từ ngôn ngữ này sang ngôn ngữ khác.
        \end{itemize}
    \item \textbf{Âm thanh và lời nói:}
        \begin{itemize}
            \item Nhận dạng giọng nói: Chuyển đổi lời nói thành văn bản.
            \item Tổng hợp giọng nói: Tạo ra giọng nói từ văn bản.
        \end{itemize}
\end{itemize}

\subsubsection{Lợi ích và bất lợi của Transfer Learning}

\textbf{Lợi ích:}

 \begin{figure}[H]
    \centering
    \includegraphics[scale = 0.2]{Images/Theoretical basis/Possible-advantages-of-transfer-learning.png}
\caption{Lợi ích của Transfer Learning}
\end{figure}


\begin{itemize}
    \item Cải thiện hiệu suất của mô hình, đặc biệt là khi dữ liệu huấn luyện hạn chế.
    \item Giảm thời gian huấn luyện và tài nguyên tính toán.
    \item Nâng cao khả năng khái quát hóa của mô hình.
\end{itemize}

\textbf{Bất lợi:}

\begin{itemize}
    \item Có thể xảy ra hiện tượng "negative transfer" nếu miền nguồn và miền đích quá khác biệt.
    \item Khó khăn trong việc lựa chọn mô hình tiền huấn luyện phù hợp.
\end{itemize}
\subsection{Giới thiệu về Self-Attention}

Self-attention là một cơ chế trong học sâu cho phép mô hình tập trung vào các phần khác nhau của dữ liệu đầu vào khi xử lý nó. Nó đã trở thành một thành phần quan trọng trong nhiều kiến trúc mạng nơ-ron hiện đại, đặc biệt là trong lĩnh vực xử lý ngôn ngữ tự nhiên.

\subsubsection{Cơ chế hoạt động của Self-Attention}

Self-attention hoạt động bằng cách tính toán mối quan hệ giữa các phần tử khác nhau trong một chuỗi. Mỗi phần tử được biểu diễn bằng một vector, và self-attention tính toán "attention weights" (trọng số chú ý) để xác định mức độ quan trọng của mỗi phần tử đối với các phần tử khác. Các trọng số này sau đó được sử dụng để tạo ra một biểu diễn mới cho mỗi phần tử, kết hợp thông tin từ các phần tử liên quan.


 \begin{figure}[H]
    \centering
    \includegraphics[scale = 0.2]{Images/Theoretical basis/self-attention.jpg}
\caption{Self Attention}
\end{figure}

\subsubsection{Các loại Self-Attention thường gặp}

Có nhiều biến thể của self-attention, mỗi biến thể có những đặc điểm và ứng dụng riêng:

* \textbf{Scaled Dot-Product Attention:} Đây là biến thể phổ biến nhất, được sử dụng trong Transformer. Nó tính toán attention weights dựa trên tích vô hướng của các vector biểu diễn.
* \textbf{Multi-Head Attention:}  Biến thể này sử dụng nhiều "head" attention song song, mỗi head tập trung vào các khía cạnh khác nhau của dữ liệu.
* \textbf{Additive Attention:} Biến thể này sử dụng một mạng nơ-ron để tính toán attention weights.

\subsubsection{Ứng dụng của Self-Attention}

Self-attention đã được ứng dụng rộng rãi trong nhiều lĩnh vực:

* \textbf{Xử lý ngôn ngữ tự nhiên:} 
    * Dịch máy
    * Tóm tắt văn bản
    * Phân tích cảm xúc
    * Hỏi đáp
* \textbf{Thị giác máy tính:}
    * Phân loại ảnh
    * Nhận dạng đối tượng
* \textbf{Các lĩnh vực khác:}
    * Sinh học
    * Âm nhạc

\subsubsection{Lợi ích của Self-Attention}

* \textbf{Nắm bắt được các phụ thuộc dài hạn:} Self-attention có thể nắm bắt được mối quan hệ giữa các phần tử cách xa nhau trong chuỗi, điều mà các mô hình RNN truyền thống gặp khó khăn.
* \textbf{Tính toán song song hiệu quả:} Self-attention có thể được tính toán song song, giúp tăng tốc độ huấn luyện và suy luận.
* \textbf{Khả năng diễn giải tốt:} Attention weights cung cấp thông tin về các phần tử quan trọng trong chuỗi, giúp hiểu rõ hơn cách mô hình đưa ra quyết định.

\subsection{Generative Adversarial Networks (GANs)}

Generative Adversarial Networks (GANs) là một lớp mô hình học sâu mạnh mẽ được sử dụng để tạo ra dữ liệu mới, giống với dữ liệu huấn luyện. GANs bao gồm hai thành phần chính: generator và discriminator, hoạt động theo một cách đối kháng - generator cố gắng sinh dữ liệu sao cho giống với dữ liệu thật nhất, discriminator cố gắng phân biệt giữa dữ liệu sinh ra và dữ liệu thật cho đến khi discrimator không thể phân biệt được nữa.

 \begin{figure}[H]
    \centering
    \includegraphics[scale = 0.2]{Images/Theoretical basis/GAN.png}
\caption{Lợi ích của Transfer Learning}
\end{figure}

\subsubsection{Kiến trúc và hoạt động của GANs}

* \textbf{Generator:} Mạng nơ-ron này nhận vào một vector nhiễu ngẫu nhiên và cố gắng tạo ra dữ liệu giả mạo giống với dữ liệu thật.
* \textbf{Discriminator:} Mạng nơ-ron này nhận vào dữ liệu (thật hoặc giả mạo) và cố gắng phân biệt giữa chúng.

Hai mạng này được huấn luyện đồng thời: generator cố gắng đánh lừa discriminator, trong khi discriminator cố gắng không bị đánh lừa. Quá trình huấn luyện này tạo ra một vòng lặp phản hồi, trong đó cả hai mạng đều cải thiện theo thời gian.

\subsubsection{Các biến thể của GANs}

Có nhiều biến thể của GANs, mỗi biến thể có những đặc điểm và ứng dụng riêng:

* \textbf{Deep Convolutional GANs (DCGANs):} Sử dụng mạng nơ-ron tích chập để tạo ra hình ảnh chất lượng cao.
* \textbf{Conditional GANs (cGANs):} Cho phép điều khiển quá trình tạo dữ liệu bằng cách cung cấp thông tin bổ sung (như nhãn lớp).
* \textbf{CycleGANs:} Cho phép chuyển đổi dữ liệu từ miền này sang miền khác (ví dụ: chuyển đổi ảnh từ mùa hè sang mùa đông).
* \textbf{Progressive Growing of GANs (PGGANs):}  Tạo ra hình ảnh có độ phân giải cao bằng cách tăng dần kích thước của mạng generator và discriminator.
* \textbf{StyleGAN:} Tạo ra hình ảnh chân thực với khả năng kiểm soát các thuộc tính tinh tế.
* \textbf{TimeGAN:} Tạo ra dữ liễu chuỗi thời gian mẫu từ tập dữ liệu đầu vào cho sẵn

\subsubsection{Ứng dụng của GANs}

GANs đã được ứng dụng trong nhiều lĩnh vực:

* \textbf{Tạo hình ảnh:} Tạo ra hình ảnh chân thực của người, vật thể, cảnh quan,...
* \textbf{Tạo dữ liệu:} Tạo ra dữ liệu tổng hợp cho các tác vụ học máy khác.
* \textbf{Chỉnh sửa ảnh:}  Thay đổi các thuộc tính của ảnh (ví dụ: thêm nụ cười, thay đổi kiểu tóc).
* \textbf{Siêu phân giải ảnh:} Tăng độ phân giải của ảnh.
* \textbf{Phục hồi ảnh:} Khôi phục các phần bị thiếu hoặc bị hỏng của ảnh.

\subsubsection{Lợi ích và hạn chế của GANs}

\textbf{Lợi ích:}

* Khả năng tạo ra dữ liệu mới, đa dạng và chân thực.
* Ứng dụng rộng rãi trong nhiều lĩnh vực.

\textbf{Hạn chế:}

* Huấn luyện GANs có thể khó khăn và không ổn định.
* Đánh giá chất lượng của dữ liệu do GANs tạo ra có thể phức tạp.

\subsection{Giới thiệu về thư viện Tensorflow}
\indent TensorFlow chính là thư viện mã nguồn mở cho machine learning nổi tiếng nhất thế giới, được phát triển bởi các nhà nghiên cứu từ Google. Việc hỗ trợ mạnh mẽ các phép toán học để tính toán trong machine learning và deep learning đã giúp việc tiếp cận các bài toán trở nên đơn giản, nhanh chóng và tiện lợi hơn nhiều. 

\indent Các hàm được dựng sẵn trong thư viện cho từng bài toán cho phép TensorFlow xây dựng được nhiều neural network. Nó còn cho phép bạn tính toán song song trên nhiều máy tính khác nhau, thậm chí trên nhiều CPU, GPU trong cùng 1 máy hay tạo ra các dataflow graph - đồ thị luồng dữ liệu để dựng nên các model. Nếu bạn muốn chọn con đường sự nghiệp trong lĩnh vực A.I. này, nắm rõ những điều cơ bản của TensorFlow thực sự rất quan trọng.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Images/Theoretical basis/TensorFlow_logo.png}
    \caption{Thư viện Tensorflow}
    \label{fig:enter-label}
\end{figure}

\subsubsection{Nguyên lý hoạt động}
\indent TensorFlow là một thư viện mã nguồn mở được thiết kế để thực hiện các phép tính số phức tạp thông qua cấu trúc đồ thị (graph). Cách hoạt động của TensorFlow dựa trên việc xây dựng và xử lý các mô hình học máy thông qua đồ thị tính toán, bao gồm các bước cơ bản sau:

\begin{itemize}
    \item \textbf{Xây dựng đồ thị tính toán:} Người dùng định nghĩa cấu trúc đồ thị, trong đó các nút (nodes) đại diện cho các phép tính toán (operations), và các cạnh (edges) biểu diễn luồng dữ liệu (dạng tensor) giữa các nút.
    \item \textbf{Định nghĩa hàm mất mát:} Hàm mất mát được sử dụng để đo lường sự khác biệt giữa đầu ra dự đoán của mô hình và giá trị thực tế. Đây là thước đo chính để tối ưu hóa mô hình.
    \item \textbf{Tối ưu hóa mô hình:} TensorFlow sử dụng các thuật toán tối ưu hóa như Gradient Descent để điều chỉnh các tham số trong mô hình, giảm giá trị của hàm mất mát.
    \item \textbf{Huấn luyện mô hình:} Dữ liệu huấn luyện được đưa vào mô hình, các tham số được cập nhật lặp đi lặp lại qua nhiều vòng huấn luyện để tối ưu hóa kết quả dự đoán.
    \item \textbf{Thực thi đồ thị qua Session:} Để thực hiện các phép tính, TensorFlow sử dụng Session, một môi trường chạy giúp thực thi đồ thị tính toán đã được xây dựng. Các session này cho phép TensorFlow phân phối các tác vụ tính toán trên nhiều thiết bị như CPU, GPU hoặc TPU.
    \item \textbf{Đánh giá mô hình:} Sau khi huấn luyện, mô hình được kiểm tra trên tập dữ liệu kiểm định để đánh giá hiệu suất và khả năng tổng quát.
    \item \textbf{Sử dụng mô hình:} Mô hình đã được huấn luyện có thể được sử dụng để dự đoán hoặc phân loại trên các dữ liệu mới, phù hợp với bài toán cụ thể.
\end{itemize}
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Images/Theoretical basis/nguyen-li-hoat-dong-tensorflow.jpeg}
    \caption{Nguyên lý hoặc động của Tensorflow}
    \label{fig:enter-label}
\end{figure}


\subsubsection{Thuộc tính cơ bản trong Tensorflow}
\indent Về cơ bản thì các thuộc tính của TensorFlow bao gồm:
\begin{itemize}
    \item \textbf{Tensors:} 
    \begin{itemize}
        \item Tensor là cấu trúc dữ liệu trung tâm trong TensorFlow, đại diện cho các mảng đa chiều với kiểu dữ liệu đồng nhất.
        \item Tensor có thể mang giá trị là dữ liệu đầu vào, kết quả trung gian hoặc đầu ra của mô hình.
    \end{itemize}
    \begin{figure}[H]
        \centering
        \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Images/Theoretical basis/tensor.png}
        \caption{Hình ảnh minh họa của một tensor và so sánh với vector và ma trận.}
        \label{fig:enter-label}
    \end{figure}
    \item \textbf{Phép tính (Operations):} 
    \begin{itemize}
        \item TensorFlow thực hiện các phép tính trên tensors thông qua các operations (toán tử).
        \item Các phép tính cơ bản bao gồm cộng, trừ, nhân, chia và nhiều phép toán học nâng cao khác.
        \item Các operations này được biểu diễn dưới dạng các nút trong đồ thị tính toán.
    \end{itemize}
    \item \textbf{Biến(Variables):} 
    \begin{itemize}
        \item Biến được sử dụng để lưu trữ các giá trị có thể thay đổi trong quá trình huấn luyện mô hình, chẳng hạn như các tham số của mô hình.
        \item Giá trị của biến có thể được khởi tạo và cập nhật trong suốt quá trình huấn luyện.
    \end{itemize}

    \item \textbf{Đồ thị(Graphs):}
    \begin{itemize}
        \item Đồ thị là một biểu đồ tính toán biểu diễn mối quan hệ giữa các phép tính và dữ liệu.
        \item TensorFlow sử dụng đồ thị để tối ưu hóa việc tính toán và triển khai mô hình trên nhiều thiết bị khác nhau, bao gồm CPU, GPU và TPU.
    \end{itemize}
    \item \textbf{Sessions:}
    \begin{itemize}
        \item Session là một phiên làm việc trong TensorFlow, nơi các phép tính trong đồ thị được thực thi.
        \item Session quản lý các biến, phép tính và thực hiện quá trình huấn luyện hoặc dự đoán.
    \end{itemize}
    \begin{figure}[H]
        \centering
        \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Images/Theoretical basis/083018_0508_WhatisTenso2.png}
        \caption{Minh họa cho 1 graph, session, operation và variable.}
        \label{fig:enter-label}
    \end{figure}
    \item \textbf{Placeholders:} 
    \begin{itemize}
        \item Placeholders là các "nơi trống" trong đồ thị, được sử dụng để nhận dữ liệu đầu vào tại thời điểm chạy.
        \item Điều này cho phép mô hình linh hoạt khi xử lý nhiều loại dữ liệu khác nhau trong quá trình huấn luyện hoặc kiểm tra.
    \end{itemize}
\end{itemize}

Các thuộc tính trên tạo thành nền tảng mạnh mẽ, giúp TensorFlow trở thành công cụ hàng đầu trong việc xây dựng, huấn luyện và triển khai các mô hình học máy hiện đại.

\subsubsection{Ưu điểm của TensorFlow}

\begin{itemize}
    \item \textbf{Tính linh hoạt cao:} 
    \begin{itemize}
        \item TensorFlow hỗ trợ nhiều loại mô hình học máy, từ học có giám sát đến học không giám sát và học tăng cường.
        \item Người dùng có thể dễ dàng tùy chỉnh mô hình để phù hợp với các bài toán cụ thể, từ mạng nơ-ron đơn giản đến các kiến trúc phức tạp như CNN, RNN, hay Transformer.
    \end{itemize}
    \item \textbf{Khả năng mở rộng mạnh mẽ:} 
    \begin{itemize}
        \item TensorFlow được thiết kế để chạy trên nhiều nền tảng khác nhau, bao gồm máy tính cá nhân, máy chủ, GPU, TPU và thậm chí là các thiết bị di động.
        \item Điều này giúp người dùng triển khai mô hình trên các môi trường khác nhau mà không cần thay đổi mã nguồn.
    \end{itemize}
    \item \textbf{Hiệu suất cao:} 
    \begin{itemize}
        \item TensorFlow tận dụng sức mạnh của phần cứng, hỗ trợ tính toán song song và tối ưu hóa hiệu suất thông qua GPU và TPU.
        \item Công cụ này cũng cung cấp các thuật toán tối ưu hóa hiệu quả, giúp giảm thời gian huấn luyện mô hình.
    \end{itemize}
    \item \textbf{Cộng đồng hỗ trợ lớn:}
    \begin{itemize}
        \item TensorFlow có một cộng đồng người dùng toàn cầu lớn mạnh, cung cấp nhiều tài liệu học tập, hướng dẫn và giải pháp cho các vấn đề kỹ thuật.
        \item Với nguồn tài liệu phong phú, người dùng dễ dàng tìm kiếm hỗ trợ từ cộng đồng hoặc các diễn đàn trực tuyến.
    \end{itemize}
    \item \textbf{Hỗ trợ triển khai mô hình:}
    \begin{itemize}
        \item TensorFlow cho phép triển khai mô hình trên nhiều nền tảng, từ máy tính cá nhân đến các ứng dụng di động, web và đám mây.
        \item TensorFlow Lite giúp tối ưu hóa mô hình cho các thiết bị có hiệu năng hạn chế như điện thoại thông minh và thiết bị IoT.
    \end{itemize}
    \item \textbf{Thư viện phong phú:} 
    \begin{itemize}
        \item TensorFlow cung cấp nhiều thư viện mở rộng như TensorFlow.js (dành cho trình duyệt web), TensorFlow Lite (dành cho thiết bị di động) và TensorFlow Extended (hỗ trợ quy trình phát triển mô hình từ đầu đến cuối).
        \item Người dùng có thể dễ dàng tích hợp các thư viện này vào dự án của mình.
    \end{itemize}
\end{itemize}

\subsection{Giới thiệu về Arduino LilyPad}
\indent Arduino LilyPad là một phiên bản đặc biệt của bo mạch Arduino, được thiết kế dành riêng cho các ứng dụng điện tử gắn vào vải (e-textiles) và thiết bị điện tử có thể đeo (wearables). Bo mạch này có cấu trúc phẳng, nhẹ và có thể được may trực tiếp vào trang phục hoặc phụ kiện bằng chỉ dẫn điện.

\indent Arduino LilyPad được phát triển bởi Leah Buechley và SparkFun Electronics, dựa trên vi điều khiển ATmega168 hoặc ATmega328V. Đây là một giải pháp lý tưởng cho các dự án điện tử sáng tạo, nơi tính thẩm mỹ và tính linh hoạt trong thiết kế được ưu tiên.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Images/Theoretical basis/lilypad_main.jpg}
    \caption{Board mạch Arduino Lilypad}
    \label{fig:enter-label}
\end{figure}

\begin{longtblr}[
  caption = {Thông số kỹ thuật của Arduino Lilypad},
]{
  width = \linewidth,
  colspec = {Q[404]Q[521]},
  hlines,
  vlines,
}
Vi điều khiển          & ATmega168 hoặc ATmega328V \\
Điện áp hoạt động      & 2.7-5.5 V                                                                                 \\
Điện áp đầu vào        & 2.7-5.5 V                                                                                 \\
Số chân I/O            & 14                                                                                        \\
Số kênh PWM            & 6                                                                                         \\
Số kênh đầu vào Analog & 6                                                                                         \\
Dòng điện mỗi chân     & 40mA                                                                                      \\
Bộ nhớ Flash           & 16 KB                                                                                     \\
SRAM                   & 1 KB                                                                                      \\
EEPROM                 & 512 bytes                                                                                 \\
Tần số xung            & 8 MHz                                                                                     
\end{longtblr}



\indent Ứng dụng tiêu biểu của Arduino Lilypad:
\begin{itemize}
    \item \textbf{Trang phục thông minh:} Arduino LilyPad có thể được sử dụng để theo dõi thông số cơ thể, điều khiển ánh sáng hoặc tích hợp cảm biến vào trang phục.
    \item \textbf{Thiết bị đeo tay:} Nó có thể làm nền tảng cho các sản phẩm như găng tay thông minh, vòng tay theo dõi sức khỏe hoặc thiết bị điều khiển bằng cử chỉ.
    \item \textbf{Dự án nghệ thuật:} LilyPad được sử dụng rộng rãi trong các dự án nghệ thuật sáng tạo, kết hợp công nghệ với thiết kế thẩm mỹ.
\end{itemize}
Với thiết kế nhỏ gọn và khả năng tích hợp cao, Arduino LilyPad là lựa chọn lý tưởng cho các nhà sáng tạo muốn kết hợp công nghệ với thời trang và các thiết bị cá nhân hóa.



\subsection{Giới thiệu về Flex sensor}


\subsubsection{Tổng quan} 

\indent Flex Sensor (Cảm biến uốn cong) là một loại cảm biến đặc biệt hoạt động dựa trên nguyên tắc thay đổi điện trở khi bị uốn cong. Loại cảm biến này thường được sử dụng để đo lường và theo dõi mức độ uốn cong hoặc góc độ của một bề mặt hoặc cấu trúc.

\indent Flex Sensor có thiết kế nhỏ gọn, linh hoạt và thường được sản xuất với hai kích thước phổ biến:
\begin{itemize}
    \item 2.2 inch (khoảng 5.588 cm)
    \item 4.5 inch (khoảng 11.43 cm)
\end{itemize}

\indent Nhờ khả năng thay đổi giá trị điện trở tỷ lệ thuận với mức độ uốn cong, cảm biến này trở thành một giải pháp hiệu quả cho nhiều ứng dụng, đặc biệt trong các dự án liên quan đến thiết bị đeo, robot hoặc hệ thống điều khiển bằng cử chỉ.

\indent Cảm biến uốn cong thường được sử dụng kết hợp với các mạch điện để chuyển đổi thay đổi điện trở thành tín hiệu điện áp, từ đó dễ dàng xử lý bằng các bộ vi điều khiển hoặc các hệ thống khác.

\indent Với độ nhạy cao và tính linh hoạt, cảm biến uốn cong là một lựa chọn lý tưởng trong các dự án cần theo dõi chuyển động hoặc đo lường độ biến dạng của bề mặt.

\begin{figure}[H]
    \centering
    \includegraphics[width=9cm]{Images/Theoretical basis/flex sensor.png}
\caption{Flex sensor}
\end{figure}

\subsubsection{Nguyên lý hoạt động}

\indent Cảm biến uốn cong hoạt động dựa trên sự thay đổi điện trở của một lớp mực dẫn đặc biệt được phủ trên bề mặt cảm biến. Khi cảm biến bị uốn cong, các đặc tính của lớp mực dẫn thay đổi, dẫn đến sự biến đổi giá trị điện trở. Cơ chế hoạt động của cảm biến bao gồm các đặc điểm chính sau:

\begin{enumerate}[-]
    \item \textbf{Trạng thái thẳng:} Khi cảm biến ở trạng thái thẳng, lớp mực dẫn không bị biến dạng, và giá trị điện trở thường dao động ở mức thấp, khoảng 25k$\Omega$.
    \item \textbf{Trạng thái uốn cong:} Khi cảm biến bị uốn, lớp mực dẫn bị kéo căng, làm giảm diện tích tiếp xúc và tăng trở kháng của nó. Ở góc uốn cong 90°, giá trị điện trở có thể tăng lên đến 100k$\Omega$ hoặc hơn, tùy thuộc vào thiết kế và loại cảm biến.
    \item \textbf{Trạng thái phục hồi:} Khi cảm biến được duỗi thẳng lại, lớp mực dẫn trở về trạng thái ban đầu, và giá trị điện trở cũng quay về mức trước đó.
\end{enumerate}

\begin{figure}[H]
    \centering
    \includegraphics[width=11cm]{Images/Theoretical basis/flex sensor 1.png}
\caption{Hình dạng uốn cong của flex sensor}
\end{figure}

\subsubsection{Đọc giá trị}

\indent Việc đọc giá trị từ cảm biến uốn cong được thực hiện thông qua một mạch điện đơn giản, thường là mạch chia điện áp. Cảm biến uốn cong được kết hợp với một điện trở cố định để tạo ra một tín hiệu điện áp thay đổi, tương ứng với mức độ uốn cong của cảm biến. Điện áp này sau đó được đo và xử lý bởi bộ vi điều khiển hoặc mạch xử lý tín hiệu.

\begin{figure}[H]
    \centering
    \includegraphics[width=5cm]{Images/Theoretical basis/flex sensor 2.jpg}
\caption{Sơ đồ nối dây của flex sensor}
\end{figure}

\indent Lưu ý rằng điện áp đầu ra mà bạn đo là mức giảm điện áp qua trở kháng kéo xuống, không phải là giảm điện áp qua cảm biến uốn cong (Flex Sensor).

\indent Chúng ta có thể sử dụng công thức sau để tính toán điện áp đầu ra (Vo).
\[ V_0 = \frac{V_{cc} \cdot R}{R + R_{\text{flex}}} \]

\indent Trong trường hợp này, điện áp đầu ra giảm khi bán kính uốn cong tăng lên.
\subsection{Giới thiệu về cảm biến con quay gia tốc}
\subsubsection{Tổng quan}
\indent Cảm biến con quay gia tốc là một thiết bị được sử dụng để đo lường sự gia tốc của một vật thể theo các trục không gian. Thiết bị này hoạt động dựa trên nguyên lý của lực quán tính, thường kết hợp với công nghệ MEMS (Micro-Electro-Mechanical Systems) để đạt được độ chính xác cao trong kích thước nhỏ gọn.

\indent Bên trong cảm biến, một khối lượng nhỏ được treo bằng các lò xo siêu nhỏ. Khi cảm biến chịu tác động của gia tốc, khối lượng này di chuyển do lực quán tính, và sự chuyển động này được chuyển đổi thành tín hiệu điện thông qua các cơ chế đo lường như:
\begin{enumerate}[-]
    \item \textbf{Hiệu ứng điện dung:} Sử dụng sự thay đổi điện dung giữa các phần tử trong cảm biến để đo mức độ di chuyển.
    \item \textbf{Hiệu ứng áp điện (Piezoelectric):} Sử dụng các vật liệu tạo điện áp khi chịu lực cơ học để đo sự dịch chuyển.
\end{enumerate}
\indent Cảm biến gia tốc thường được thiết kế để đo gia tốc theo ba trục: X, Y và Z. Điều này giúp xác định chính xác chuyển động, tư thế hoặc vị trí của vật thể trong không gian.

\subsubsection{Nguyên lý hoạt động}
\subsubsubsection{Hiệu ứng điện dung:}
\indent Cấu trúc lò xo - khối nặng - giảm xóc: Cấu trúc này chuyển đổi gia tốc của khung cảm biến thành sự dịch chuyển của khối nặng chứng minh, và phương pháp cảm biến điện dung được áp dụng để chuyển đổi sự dịch chuyển này thành tín hiệu điện tử tỷ lệ với gia tốc được áp dụng.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Images/Theoretical basis/168_Introduction_to_Capacitive_Acceleration_Sensors_Figure_3.jpeg}
    \caption{Cấu trúc của một cảm biến gia tốc sử dụng phương pháp điện dung}
    \label{fig:capacitive_sensor}
\end{figure}
\indent Phương pháp cảm biến điện dung: Có hai bản điện cực được gắn cố định vào khung cảm biến cùng với một điện cực di động được kết nối với khối lượng tham chiếu. Thiết kế này hình thành hai tụ điện biến thiên C1 và C2, như được hiển thị trong hình \ref{fig:capacitive_sensor}.

\indent Khi khối lượng tham chiếu di chuyển theo một hướng dưới ảnh hưởng của gia tốc, điện dung giữa điện cực di động và một trong hai điện cực cố định tăng lên trong khi điện dung của tụ điện kia giảm xuống. Bằng cách đo đạc sự thay đổi điện dung của hai tụ điện trên, và kết hợp với khối lượng tham chiếu có sẳn ta có thể tính toán được gia tốc đầu vào.

\subsubsubsection{Hiệu ứng áp điện (Piezoelectric):}
\indent Hiệu ứng Piezoelectric là hiện tượng mà một số vật liệu nhất định có khả năng tạo ra điện tích khi chịu áp lực cơ học. Từ “Piezoelectric” bắt nguồn từ từ tiếng Hy Lạp “piezein”, có nghĩa là “ấn hoặc nén”, mô tả chính xác quá trình tạo ra điện năng thông qua áp lực.

\indent Hiệu ứng này xảy ra ở mức độ vi mô, khi áp dụng một lực cơ học dẫn đến sự di chuyển của các điện tích dương và âm trong cấu trúc tinh thể của vật liệu. Sự dịch chuyển này tạo ra một cực điện và hình thành một điên áp đi qua vật liệu.

\indent Hiệu ứng Piezoelectric là một quá trình có thể đảo ngược: vật liệu thể hiện hiệu ứng piezoelectric cũng sẽ bị biến dạng cơ học nếu đặt một điện áp đi qua nó.

Ví dụ, các tinh thể titanate zirconate chì sẽ tạo ra dòng điện Piezoelectric khi cấu trúc tĩnh của chúng bị biến dạng khoảng 0,1\% so với kích thước gốc. Ngược lại, những tinh thể giống như vậy sẽ thay đổi khoảng 0,1\% kích thước tĩnh của chúng khi áp dụng một điện trường bên ngoài.

\indent Hiệu ứng Piezoelectric đã được khai thác trong nhiều ứng dụng hữu ích, bao gồm sản xuất và phát hiện âm thanh, in phun piezoelectric, tạo ra điện năng điện áp cao, như một bộ tạo xung trong các thiết bị điện tử, trong microbalances, để điều khiển một đầu phun siêu âm, và trong việc tập trung siêu mịn của các bộ phận quang học.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Images/Theoretical basis/intro_piezo_accelerometers_figure_1.jpeg}
    \caption{Hiệu ứng Piezoelectric}
    \label{fig:pio_prin}
\end{figure}
\indent Cấu trúc của cảm biến gia tốc bao gồm một phần tử piezoelectric để kết nối một lượng khối lượng cố định với thân cảm biến. Khi khung cảm biến tăng tốc do lực bên ngoài, khối lượng tham chiếu có xu hướng giữ nguyên vị trí do quán tính và làm biến dạng nhẹ phần tử piezoelectric.
\indent Nếu nối hai điện cực với nhau thông qua một sợi dây như mô tả trong \ref{fig:pio_prin}, thì các electron tự do trong dây dẫn sẽ chảy về phía điện cực tích điện dương và tạo ra một dòng điện. Dòng điện này tích tụ các electron tự do trên điện cực dương và tạo ra một điện trường ngược hướng với trường ban đầu được tạo ra bởi hiệu ứng Piezoelectric.

\indent Hiệu ứng này giải thích tại sao dòng điện do lực tĩnh tạo ra chỉ có thể tồn tại trong một khoảng thời gian ngắn. Dòng điện tiếp tục cho đến khi điện trường do sự tích tụ của các electron tự do triệt tiêu trường khỏi hiệu ứng Piezoelectric.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Images/Theoretical basis/intro_piezo_accelerometers_figure_2.jpeg}
    \caption{Các kiểu thiết kế cơ học của cảm biến gia tốc}
    \label{fig:piozDesin}
\end{figure}
\indent Các kiểu thiết kế cơ học phổ biến của cảm biến gia tốc sử dụng hiệu ứng Piezoelectric:
\begin{itemize}
    \item \textbf{Thiết kế theo chế độ nén:} THiết kế này rất đơn giản, chỉ bao gồm một bản thiết bị có hiệu ứng Piezoelectric và một khối lượng tham chiếu. Khi xảy ra gia tốc, lực quán tính sẽ làm cho khối lượng tham chiếu ép chặt vào tấm vật liệu áp điện từ đó tạo ra dòng điện.
    \item \textbf{Thiết theo chế độ trượt:} Gồm hai loại là trượt trên một tấm phẳng hoặc thiết kế trượt trên một khối hình nhẫn. Về cơ bản thì hai kiểu thiết kế này có cùng ngueyen lý hoạt động. Tinh thể được kẹp giữa trụ trung tâm và khối lượng thâm chiếu bên ngoài. Khối lượng càng nhiều thì lực trượt tác dụng lên tinh thể càng lớn đối với một gia tốc nhất định. Cấu trúc này giúp gia tốc kế cứng chắc, tạo ra dải tần số cao và do tinh thể không tiếp xúc trực tiếp với  cảm biến nên các hiệu ứng biến dạng và chuyển tiếp nhiệt được giảm thiểu.
    \item \textbf{Thiết kế theo chế độ uốn:} thiết kế này sử dụng các tấm tinh thể có hình chữ nhật hoặc hình đĩa. Sự uốn cong của tinh thể có thể xảy ra do khối lượng của chính tinh thể đối lập với gia tốc hoặc để tăng cường sự uốn cong, trọng lượng bổ sung có thể được kẹp hoặc liên kết với tinh thể. Gia tốc kế ở chế độ uốn ít cứng hơn khi so sánh với thiết kế nén hoặc trượt, cung cấp cho chúng dải tần số giới hạn. Ngoài ra, do tinh thể phải chịu mức độ căng áp lực cao nên chúng dễ bị hỏng hơn các loại khác nếu bị sốc hoặc rung quá mức.
\end{itemize}

\subsubsection{Giới thiệu về module cảm biến ITG 3200}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth,height=\textheight,keepaspectratio]{Images/Theoretical basis/ITG3200.jpg}
    \caption{Cảm biến gia tốc góc ITG 3200}
    \label{fig:capacitive_sensor}
\end{figure}
\indent Module cảm biến ITG 3200 là một loại cảm biến con quay gia tốc 3 trục, sử dụng công nghệ MEMS để đo góc quay và vận tốc góc. Cảm biến này có khả năng cung cấp dữ liệu về các chuyển động xoay trên ba trục không gian X, Y và Z. ITG 3200 có độ chính xác cao và tốc độ đáp ứng nhanh, phù hợp với nhiều ứng dụng yêu cầu đo đạc chuyển động như điều khiển robot, máy bay không người lái (drone), hệ thống ổn định, và các thiết bị đo lường khác.
\\
\textbf{Các đặc điểm chính của ITG 3200:}
\begin{itemize}
\item \textbf{Cảm biến 3 trục:} Đo lường góc quay và vận tốc góc trên ba trục không gian.
\item \textbf{Độ phân giải cao:} Cảm biến có thể cung cấp các giá trị đo chính xác với độ phân giải lên đến 14-bit.
 \item \textbf{Tốc độ lấy mẫu:} Cảm biến hỗ trợ tốc độ lấy mẫu lên đến 8 kHz, giúp thu thập dữ liệu nhanh và chính xác.
 \item \textbf{Giao tiếp I2C:} ITG 3200 sử dụng giao tiếp I2C để truyền tải dữ liệu, giúp dễ dàng kết nối với các vi điều khiển và hệ thống nhúng.
\item \textbf{Nguồn cấp}: Được cấp nguồn từ 2.3V đến 3.4V, giúp tiết kiệm năng lượng trong các ứng dụng di động hoặc thiết bị nhúng.
\item \textbf{Bộ lọc tích hợp} Cảm biến này có tích hợp bộ lọc kỹ thuật số để giảm nhiễu và cải thiện độ chính xác của dữ liệu.
\end{itemize}
\indent \textbf{Ứng dụng của ITG 3200:}
\begin{itemize}
\item \textbf{Điều khiển ổn định:} ITG 3200 được sử dụng trong các hệ thống ổn định để đo chuyển động quay, giúp duy trì sự cân bằng của các thiết bị như drone và robot.
\item \textbf{Thiết bị đo lường:} Sử dụng trong các thiết bị đo đạc góc quay chính xác, chẳng hạn như thiết bị đeo thông minh và các hệ thống tự động.
 \item \textbf{Các hệ thống điều khiển:} Được sử dụng trong các hệ thống điều khiển tự động, giúp phát hiện và xử lý chuyển động quay trong thời gian thực.
\end{itemize}

\subsection{Giới thiệu về module bluetooth HC05}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth,height=\textheight,keepaspectratio]{Images/Theoretical basis/hc05.jpg}
    \caption{module bluetooth HC-05}
    \label{fig:capacitive_sensor}
\end{figure}

\indent Module Bluetooth HC-05 là một mô-đun giao tiếp không dây sử dụng chuẩn Bluetooth 2.0, cho phép kết nối các thiết bị điện tử với nhau qua giao thức Bluetooth. Đây là một module phổ biến và dễ sử dụng trong các dự án điện tử và IoT (Internet of Things), giúp các thiết bị như vi điều khiển, cảm biến hoặc các thiết bị di động kết nối với nhau một cách thuận tiện.
\\
\textbf{Các đặc điểm chính của HC-05:}
\begin{itemize}
\item \textbf{Chế độ hoạt động:} HC-05 hỗ trợ hai chế độ hoạt động: Master (chủ) và Slave (phụ). Chế độ Master cho phép HC-05 kết nối với các thiết bị khác, trong khi chế độ Slave cho phép module kết nối với một thiết bị khác như điện thoại hoặc máy tính.
\item \textbf{Giao tiếp Serial (UART):} HC-05 sử dụng giao tiếp UART (Universal Asynchronous Receiver/Transmitter) để trao đổi dữ liệu với các vi điều khiển và các thiết bị điện tử khác, giúp dễ dàng tích hợp vào các mạch điện tử.
 \item \textbf{Khoảng cách truyền tín hiệu:} HC-05 có thể truyền tín hiệu Bluetooth trong phạm vi lên tới 10 mét, tùy thuộc vào môi trường và các yếu tố xung quanh.
\item \textbf{Nguồn cấp}: Module hoạt động với nguồn cung cấp từ 3.3V đến 5V, tương thích với các hệ thống sử dụng vi điều khiển phổ biến như Arduino.
\item \textbf{Tốc độ truyền dữ liệu:} HC-05 có tốc độ truyền dữ liệu lên đến 3 Mbps, cho phép truyền tải thông tin nhanh chóng và hiệu quả giữa các thiết bị.
\end{itemize}
\textbf{Ứng dụng của HC-05:}
\begin{itemize}
\item \textbf{Kết nối không dây:} HC-05 có thể được sử dụng trong các dự án yêu cầu kết nối không dây giữa các thiết bị như Arduino với điện thoại thông minh, máy tính hoặc các thiết bị khác hỗ trợ Bluetooth.
\item \textbf{Điều khiển từ xa:} Module này được ứng dụng trong các hệ thống điều khiển từ xa, giúp người dùng điều khiển thiết bị điện tử thông qua ứng dụng di động hoặc máy tính.
 \item \textbf{Hệ thống IoT:} HC-05 là một lựa chọn phổ biến trong các hệ thống IoT, nơi các thiết bị cần giao tiếp với nhau qua mạng Bluetooth để truyền dữ liệu hoặc điều khiển từ xa.
\end{itemize}
\subsection{Giới thiệu về ngôn ngữ ký hiệu}
\indent Ngôn ngữ ký hiệu là phương tiện giao tiếp chính thức của cộng đồng người khiếm thính, được sử dụng để biểu đạt ý tưởng và cảm xúc thông qua các cử chỉ tay và động tác cơ thể. Mỗi ngôn ngữ ký hiệu có cấu trúc ngữ pháp và từ vựng riêng, khác biệt với ngôn ngữ nói và thường được sử dụng bởi những người không thể nghe hoặc không thể nói.

\indent Ngôn ngữ ký hiệu không chỉ bao gồm các động tác tay mà còn sử dụng biểu cảm khuôn mặt, cử chỉ của các bộ phận cơ thể như mắt, đầu và cơ thể để truyền đạt thông điệp. Điều này giúp ngôn ngữ ký hiệu trở thành một hệ thống giao tiếp toàn diện, có thể biểu đạt đầy đủ các ý tưởng phức tạp như trong ngôn ngữ nói.

\indent Ngôn ngữ ký hiệu ở Việt Nam đã được hình thành từ rất lâu. Nhưng do trước đây chưa có nhà khoa học nào tìm hiểu,nghiên cứu về nó nên người Việt Nam không nghĩ và đã không xem những dấu hiệu mà người điếc sử dụng là ngôn ngữ. Họ cho rằng đó chỉ là những điệu bộ khua tay của người điếc để cố gắng giao tiếp do thiếu ngôn ngữ. Mãi đến năm 1996, một tiến sĩ ngôn ngữ học người Mỹ James C. Woodward, người đã từng làm việc với William Stokoe tại trường đại học Gallaudet của Mỹ, đã sang Việt Nam thực hiện nghiên cứu về ngôn ngữ ký hiệu của cộng đồng người điếc ở Việt Nam. Theo nghiên cứu của ông, ở Việt Nam hiện có ít nhất 3 ngôn ngữ ký hiệu phổ biến (được cộng đồng người điếc sử dụng nhiều nhất). Ông đã dùng tên của những địa danh này để đặt tên cho 3 ngôn ngữ ký hiệu đó: Ngôn ngữ ký hiệu Hà Nội, ngôn ngữ ký hiệu Hải Phòng, và ngôn ngữ ký hiệu Thành phố Hồ Chí Minh.

\indent Sau đó, đã có thêm những dự án ở Việt Nam:dự án Giáo dục hòa nhập cho trẻ điếc 1998-2001 (Viện Khoa học Giáo dục- tổ chức Pearl S. Buck, Int), dư án Giáo dục trung học và đại học cho người Điếc Việt Nam 2000 cho đến hiện tại (Sở GD-ĐT Đồng Nai và GS TS JAMES C. WOODWARD) để thực hiện việc thu thập lại những dấu hiệu của người điếc Việt Nam và tìm hiểu về ngữ pháp của ngôn ngữ này. Công việc này đã kích thích thêm nhiều nhà khoa học ở Việt Nam cũng bắt đầu tìm hiểu về ngữ pháp của ngôn ngữ ký hiệu Việt Nam.

\indent Để một người có thể diễn đạt được ngôn ngữ ký hiệu đòi hỏi một hoặc nhiều yếu tố dưới đây:
\begin{itemize}
    \item \textbf{Vị trí làm kí hiệu:} Vị trí làm kí hiệu là vị trí của bàn tay so với cơ thể khi làm kí hiệu. Vị trí làm kí hiệu khác nhau thể hiện những ý nghĩa khác nhau. Khoảng không gian để thể hiện kí hiệu được giới hạn từ đỉnh đầu, khoảng không gian phía trước cơ thể mở rộng đến độ rộng của hai khuỷu tay ở hai phía, lưng và hông.
    \item  \textbf{Hình dạng bàn tay:} Hình dạng bàn tay là các hình dạng khác nhau của bàn tay khi thực hiện kí hiệu.
    \item \textbf{Sự chuyển động của tay:} Sự chuyển động của tay là những cử động của tay khi làm kí hiệu, bao gồm chuyển động đơn (một chuyển động trong một lần làm kí hiệu), và chuyển động kép (nhiều chuyển động trong một lần làm kí hiệu). Nhìn vào mũi tên trong hình vẽ của kí hiệu chúng ta biết được sự chuyển động của tay.
    \item \textbf{Chiều hướng của tay:} Chiều hướng của tay khi làm kí hiệu bao gồm chiều hướng của lòng bàn tay và chiều hướng của các ngón tay.
    \item \textbf{Sự diễn tả không bằng tay:} Sự diễn tả không bằng tay là những cử chỉ, điệu bộ, nét mặt, cử động của cơ thể kèm theo.
\end{itemize}
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{Images/Theoretical basis/bangsochu.jpg}
    \caption{Bảng ngôn ngữ kí hiệu}
    \label{fig:enter-label}
\end{figure}


